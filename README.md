# Dissertation
Sign2Text: Parametric analysis to build simplest transformer for sign language translation

In this dissertation, we explore the application of Transformer models for translating German Sign Language (DGS) gestures into textual descriptions. 
The primary objective is to identify a simplified Transformer architecture that achieves competitive performance with computational efficiency. 
This research is conducted using the RWTH-PHOENIX-Weather 2014 dataset consisting of video sequences of DGS gestures recorded from German public television broadcasts.
A critical aspect we focus on is the pre-processing of video frames to extract key body pose landmarks using MediaPipe. 
To determine the most effective transformer, parametric analysis was done by varying four key components of the transformerâ€™s configurations which include number of layers, attention head, input and embedding dimensions. In total, eight transformers were developed and evaluated. 
Performance was measured using BLEU and ROUGE scores, standard metrics for assessing text quality generated by machine translation systems. 
The results show that not only were we able to build a simple and effective Transformer, but in some cases, our models outperformed state-of-the-art models. 
The findings of this dissertation contribute to the field of sign language processing by showing the potential of Transformer models and the importance of balancing model complexity with performance to develop more accessible and efficient translation systems.
